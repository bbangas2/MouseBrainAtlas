{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from data_manager import *\n",
    "from metadata import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.transform import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_masks_normalized = bp.unpack_ndarray_file('/home/yuncong/csd395/CSHL_cells/fractal_dim/cell_masks_normalized.bp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cells = len(cell_masks_normalized)\n",
    "print n_cells, 'cells'\n",
    "\n",
    "cell_masks_normalized_flattened = np.reshape(cell_masks_normalized, (len(cell_masks_normalized), -1))\n",
    "cell_masks_normalized_flattened.shape\n",
    "\n",
    "cell_masks_normalized_size = cell_masks_normalized_flattened.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "memberCount = np.bincount(indices_of_closest_seed, minlength=len(seeds))\n",
    "seedIndices_sorted_by_memberCount = np.argsort(memberCount)[::-1]\n",
    "memberCount_sorted = memberCount[seedIndices_sorted_by_memberCount]\n",
    "seeds_ranked_by_memberCount = seeds[seedIndices_sorted_by_memberCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(memberCount_sorted) / float(n_cells));\n",
    "plt.xlabel('top # seeds');\n",
    "plt.ylabel('percentage coverage');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def compute_jaccard_list_with_all(seed_indices):\n",
    "\n",
    "    pool = Pool(14)\n",
    "    affinities_to_seeds = pool.map(compute_jaccard_with_i, seed_indices)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return np.asarray(affinities_to_seeds)\n",
    "\n",
    "def compute_jaccard_with_i_list(i, indices):\n",
    "    intersections = cell_masks_normalized_flattened[indices[:,None], cell_masks_normalized_flattened[i]].sum(axis=1)\n",
    "    unions = cell_masks_normalized_size[i] + cell_masks_normalized_size[indices] - intersections\n",
    "    scores = intersections.astype(np.float)/unions\n",
    "    return scores\n",
    "    \n",
    "def compute_jaccard_pairwise(indices, square_form=True, parallel=True):\n",
    "    n = len(indices)\n",
    "\n",
    "    if parallel:\n",
    "        pool = Pool(16)\n",
    "        pairwise_scores = pool.map(lambda x: compute_jaccard_with_i_list(x[0],x[1]), \n",
    "                                   [(indices[i], indices[i+1:]) for i in range(n)])\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        pairwise_scores = [compute_jaccard_with_i_list(indices[i], indices[i+1:]) for i in range(n)]\n",
    "        \n",
    "    if square_form:\n",
    "        return squareform(np.concatenate(pairwise_scores))\n",
    "    else:\n",
    "        return pairwise_scores\n",
    "\n",
    "def compute_jaccard_with_i(i, upper=False):\n",
    "    if upper:\n",
    "        intersections_with_i = cell_masks_normalized_flattened[i+1:, cell_masks_normalized_flattened[i]].sum(axis=1)\n",
    "        unions_with_i = cell_masks_normalized_size[i] + cell_masks_normalized_size[i+1:] - intersections_with_i\n",
    "    else:\n",
    "        intersections_with_i = cell_masks_normalized_flattened[:, cell_masks_normalized_flattened[i]].sum(axis=1)\n",
    "        unions_with_i = cell_masks_normalized_size[i] + cell_masks_normalized_size - intersections_with_i\n",
    "        \n",
    "    return intersections_with_i.astype(np.float)/unions_with_i\n",
    "\n",
    "def compute_jaccard_with_template(template):\n",
    "    intersections_with_template = [template[m].sum() for m in cell_masks_normalized_flattened]\n",
    "    unions_with_template = (template + cell_masks_normalized_size - intersections_with_template)\n",
    "    return intersections_with_template.astype(np.float)/unions_with_template\n",
    "\n",
    "def compute_jaccard_with_i_sparse(i, upper=False, threshold=.85, n_neighbors=10):\n",
    "    if upper:\n",
    "        scores = compute_jaccard_with_i(i, upper=True)\n",
    "        nearest_neighbors = np.where(scores > threshold)[0]\n",
    "        return i+1+nearest_neighbors, scores[nearest_neighbors]\n",
    "    else:\n",
    "        scores = compute_jaccard_with_i(i, upper=False)\n",
    "        nearest_neighbors = np.argsort(scores)[::-1][:10]\n",
    "        return nearest_neighbors, scores[nearest_neighbors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_per_batch = 1000\n",
    "n_batches = n_cells / data_per_batch\n",
    "print 'n_batches =', n_batches\n",
    "slave_start_indices = np.linspace(0, n_cells, n_batches+1).astype(np.int)\n",
    "\n",
    "for batch_index in range(n_batches):\n",
    "    \n",
    "    print batch_index\n",
    "    t = time.time()\n",
    "\n",
    "    begin_data_index = slave_start_indices[batch_index]\n",
    "    end_data_index = slave_start_indices[batch_index+1]-1\n",
    "    scores = compute_jaccard_list_with_all(range(begin_data_index, end_data_index+1))\n",
    "#     scores[scores < threshold] = 0\n",
    "    bp.pack_ndarray_file(scores.astype(np.float16), '/home/yuncong/csd395/CSHL_cells/fractal_dim/pairwise_scores_%d_%d.bp' % (begin_data_index,\n",
    "                                                                                                          end_data_index))\n",
    "    \n",
    "    sys.stderr.write('Compute pairwise affinities: %f s.\\n' % (time.time()-t)) # 44s / 1000 x 200k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sparse\n",
    "\n",
    "affinities_mat_full = dok_matrix((n_cells, n_cells), dtype=np.float16)\n",
    "\n",
    "data_per_batch = 1000\n",
    "n_batches = n_cells / data_per_batch\n",
    "print 'n_batches =', n_batches\n",
    "slave_start_indices = np.linspace(0, n_cells, n_batches+1).astype(np.int)\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "for batch_index in range(n_batches):\n",
    "    \n",
    "    print batch_index\n",
    "    t = time.time()\n",
    "\n",
    "    begin_data_index = slave_start_indices[batch_index]\n",
    "    end_data_index = slave_start_indices[batch_index+1]-1\n",
    "    \n",
    "    scores = bp.unpack_ndarray_file('/home/yuncong/csd395/CSHL_cells/fractal_dim/pairwise_scores_%d_%d.bp' % (begin_data_index,\n",
    "                                                                                                          end_data_index))\n",
    "    \n",
    "    sys.stderr.write('Load pairwise affinities: %f s.\\n' % (time.time()-t)) # 15s / 1000 x 200k\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "#     nearest_neighbors_cols = np.argsort(scores, axis=1)[:, ::-1][:, :10]\n",
    "#     for i in range\n",
    "    \n",
    "    nearest_neighbors_rows, nearest_neighbors_cols = np.where(scores > threshold)\n",
    "    \n",
    "    sys.stderr.write('Load pairwise affinities: %f s.\\n' % (time.time()-t)) # 15s / 1000 x 200k\n",
    "    \n",
    "    t = time.time()\n",
    "    affinities_mat_full[begin_data_index + nearest_neighbors_rows, nearest_neighbors_cols] = scores[nearest_neighbors_rows, nearest_neighbors_cols]\n",
    "    \n",
    "    sys.stderr.write('Load pairwise affinities: %f s.\\n' % (time.time()-t)) # 15s / 1000 x 200k\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse.linalg\n",
    "\n",
    "D = np.sum(affinities_mat_full, axis=1)\n",
    "L = D - affinities_mat_full\n",
    "eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(L, M=D)\n",
    "embedding = eigenvectors[:7, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full Spectral Clutering\n",
    "\n",
    "import scipy.linalg\n",
    "\n",
    "distance_mat_full = squareform(pdist(data))\n",
    "affinities_mat_full = np.exp(-distance_mat_full**2/10.)\n",
    "\n",
    "D = np.diag(np.sum(affinities_mat_full, axis=1))\n",
    "L = D - affinities_mat_full\n",
    "eigenvalues, eigenvectors = scipy.linalg.eigh(L, D)\n",
    "nvec = 2\n",
    "E_original_order = eigenvectors[:, 1:1+nvec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_classes)\n",
    "kmeans.fit(E_original_order);\n",
    "\n",
    "print np.bincount(kmeans.labels_, minlength=n_classes)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    indices = np.where(kmeans.labels_ == i)[0]\n",
    "    plt.scatter(data[indices,0], data[indices,1], c=colors[i]);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our data, Nystroem extension\n",
    "# https://people.eecs.berkeley.edu/~malik/papers/FBCM-nystrom.pdf\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "n_seeds = 200\n",
    "sampled = seeds_ranked_by_memberCount[:n_seeds].copy()\n",
    "\n",
    "affinities_with_samples = compute_jaccard_list_with_all(sampled)\n",
    "\n",
    "sys.stderr.write('Compute pairwise affinities (with samples): %f s.\\n' % (time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonsampled = np.setdiff1d(range(affinities_with_samples.shape[1]), sampled)\n",
    "permutation = np.r_[sampled, nonsampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "A = affinities_with_samples[:, sampled].copy()\n",
    "B = affinities_with_samples[:, nonsampled].copy()\n",
    "\n",
    "d1 = np.sum(np.c_[A, B], axis=1)\n",
    "Ai = np.linalg.inv(A)\n",
    "d2 = np.sum(B, axis=0) + np.dot(B.T, np.dot(Ai, np.sum(B, axis=1)))\n",
    "dhat_si = np.sqrt(1./np.r_[d1, d2])\n",
    "A = A*np.outer(dhat_si[:n_seeds], dhat_si[:n_seeds])\n",
    "B = B*np.outer(dhat_si[:n_seeds], dhat_si[n_seeds:])\n",
    "\n",
    "Asi = sqrtm(Ai)\n",
    "\n",
    "M = np.dot(B.T, Asi)\n",
    "S = A + np.dot(M.T, M)\n",
    "\n",
    "U, L, T = np.linalg.svd(S)\n",
    "\n",
    "V = np.dot(np.vstack([A, B.T]), np.dot(Asi, np.dot(U, np.linalg.inv(np.diag(np.sqrt(L))))))\n",
    "\n",
    "sys.stderr.write('Nystroem: %f s.\\n' % (time.time()-t)) # 60s / 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_allEig = V[:,1:]/V[:,0][:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_allEig_original_order = np.zeros_like(E_allEig)\n",
    "E_allEig_original_order[permutation] = E_allEig\n",
    "\n",
    "bp.pack_ndarray_file(E_allEig_original_order, \n",
    "                     '/home/yuncong/csd395/CSHL_cells/fractal_dim/embeddingAllEigen_nystromSample%d.bp' % n_seeds)\n",
    "\n",
    "# print E_allEig_original_order.mean(axis=0)\n",
    "# print E_allEig_original_order.std(axis=0)\n",
    "\n",
    "E_allEig_original_order_normalized = (E_allEig_original_order-E_allEig_original_order.mean(axis=0))/E_allEig_original_order.std(axis=0)\n",
    "\n",
    "bp.pack_ndarray_file(E_allEig_original_order_normalized, \n",
    "                     '/home/yuncong/csd395/CSHL_cells/fractal_dim/embeddingAllEigenNormalized_nystromSample%d.bp' % n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
